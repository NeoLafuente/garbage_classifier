import os
import random
import zipfile

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from matplotlib.offsetbox import OffsetImage, AnnotationBbox
from PIL import Image
from scipy.cluster.hierarchy import dendrogram, linkage
from scipy.spatial.distance import pdist, squareform

"""
For import custom classes, we have to change root path:
import sys
sys.path.append(os.path.abspath(os.path.join(os.getcwd(), "..")))
"""





ROOT_PATH = os.path.join("..", "data", "raw")
DATASET_PATH = os.path.join(ROOT_PATH, "Garbage_Dataset_Classification")
ZIP_FILE = os.path.join(ROOT_PATH, "garbage-dataset.zip")

# Direct Kaggle download link
KAGGLE_URL = "https://www.kaggle.com/api/v1/datasets/download/zlatan599/garbage-dataset-classification"


def download_with_curl():
    """
    Download Kaggle dataset using curl + API credentials.
    Requires: ~/.kaggle/kaggle.json with username + key
    """
    print("Downloading dataset with curl...")

    # Make sure ~/.kaggle exists and is secure
    os.makedirs(os.path.expanduser("~/.kaggle"), exist_ok=True)
    os.chmod(os.path.expanduser("~/.kaggle"), 0o700)

    # Run curl command (requires kaggle.json for auth)
    cmd = f"curl -L -o {ZIP_FILE} -u `jq -r .username ~/.kaggle/kaggle.json`:`jq -r .key ~/.kaggle/kaggle.json` {KAGGLE_URL}"
    os.system(cmd)

    print("Extracting dataset...")
    with zipfile.ZipFile(ZIP_FILE, "r") as zip_ref:
        zip_ref.extractall(ROOT_PATH)
    
    os.remove(ZIP_FILE)


if not os.path.exists(DATASET_PATH):
    download_with_curl()
else:
    print(f"{DATASET_PATH} already exists, nothing to do.")








for root, dirs, files in os.walk(DATASET_PATH):
    print(root, len(files))





# Load metadata
metadata_path = os.path.join(DATASET_PATH, "metadata.csv")
df = pd.read_csv(metadata_path)

# Quick look at the data
print(df.head())
print()
print(df['label'].value_counts())





def plot_random_examples_per_class(df, dataset_path, filename=None):
    """
    Plots a random image from each class with colored borders using seaborn palette.

    df: pandas DataFrame with a 'label' column
    dataset_path: path to folder containing dataset images
    filename (optional): filename of the PDF file where shown image will be dumped
    """
    classes = df['label'].unique()
    n_classes = len(classes)
    
    # Seaborn palette for consistent class colors
    palette = sns.color_palette("tab10", n_classes)
    class_colors = {cls: palette[i] for i, cls in enumerate(classes)}
    
    # Determine grid size
    cols = 3
    rows = (n_classes + cols - 1) // cols
    plt.figure(figsize=(cols*4, rows*4))
    
    for i, cls in enumerate(classes):
        img_filename = df[df['label']==cls].sample(1).iloc[0]['filename']
        img_path = os.path.join(dataset_path, "images", cls, img_filename)
        img = Image.open(img_path)
        
        ax = plt.subplot(rows, cols, i+1)
        ax.imshow(img)
        ax.set_title(cls, fontsize=14, color=class_colors[cls])
        ax.axis("off")
        
        # Add colored border
        for spine in ax.spines.values():
            spine.set_edgecolor(class_colors[cls])
            spine.set_linewidth(4)
    
    plt.tight_layout()
    if filename != None:
        plt.savefig(filename, dpi=150)
    plt.show()


plot_random_examples_per_class(
    df,
    DATASET_PATH,
    os.path.join('..', 'reports', 'figures', 'EDA', 'random_examples_per_class.pdf')
)





def plot_class_distribution(df, filename=None):
    """
    Plots the class distribution using seaborn countplot.
    
    df: pandas DataFrame with a 'label' column
    filename (optional): filename of the PDF file where shown countplot will be dumped
    """
    plt.figure(figsize=(8, 5))
    sns.countplot(
        data=df,
        x="label",
        hue="label",  # assign hue
        order=df['label'].value_counts().index,
        palette="tab10",
        legend=False  # disable redundant legend
    )
    plt.title("Class Distribution", fontsize=16)
    plt.xlabel("Class", fontsize=12)
    plt.ylabel("Count", fontsize=12)
    plt.xticks(rotation=45)
    plt.tight_layout()
    if filename != None:
        plt.savefig(filename, dpi=150)
    plt.show()


plot_class_distribution(
    df,
    os.path.join('..', 'reports', 'figures', 'EDA', 'class_distribution.pdf')
)








def plot_image_size_scatter(df, dataset_path, filename=None):
    """
    Plots a scatter plot of image dimensions (Width vs Height),
    colored by label and using different markers for each class.
    
    df: pandas DataFrame with a 'label' column
    dataset_path: path to folder containing dataset images
    filename (optional): filename of the PDF file where shown scatter plot will be dumped
    """
    # Extract image sizes
    widths, heights, labels = [], [], []
    for _, row in df.iterrows():
        img_path = os.path.join(dataset_path, "images", row['label'], row['filename'])
        try:
            with Image.open(img_path) as img:
                w, h = img.size
        except:
            continue
        widths.append(w)
        heights.append(h)
        labels.append(row['label'])
    
    # Build a new DataFrame with sizes
    size_df = pd.DataFrame({
        "Width": widths,
        "Height": heights,
        "Label": labels
    })
    
    # Define markers (cycled if there are more classes than markers)
    markers = ["o", "s", "X", "D", "^", "v"]
    
    # Create scatterplot
    plt.figure(figsize=(8, 6))
    sns.scatterplot(
        data=size_df,
        x="Width",
        y="Height",
        hue="Label",
        style="Label",  # different markers
        palette="tab10",
        markers=markers
    )
    
    plt.title("Image Dimensions per Class", fontsize=16)
    plt.xlabel("Width", fontsize=12)
    plt.ylabel("Height", fontsize=12)
    plt.legend(title="Class", bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.tight_layout()
    if filename != None:
        plt.savefig(filename, dpi=150)
    plt.show()

    print(f"Image sizes:")
    print(f"Min width: {np.min(widths)}")
    print(f"Max width: {np.max(widths)}")
    print(f"Min height: {np.min(heights)}")
    print(f"Max height: {np.max(heights)}")


plot_image_size_scatter(
    df,
    DATASET_PATH
)








def plot_mean_images_per_class(df, dataset_path, filename=None):
    """
    Computes and plots the mean image for each class.
    
    df: pandas DataFrame with a 'label' column
    dataset_path: path to folder containing dataset images
    filename (optional): filename of the PDF file where shown image will be dumped
    """
    classes = df['label'].unique()
    mean_images = {}
    
    for cls in classes:
        imgs = []
        subset = df[df['label'] == cls]
        
        for _, row in subset.iterrows():
            img_path = os.path.join(dataset_path, "images", row['label'], row['filename'])
            try:
                img = Image.open(img_path).convert("RGB")
                imgs.append(np.array(img, dtype=np.float32))
            except:
                continue
        
        if imgs:
            mean_img = np.mean(imgs, axis=0) / 255.0  # normalize to [0,1]
            mean_images[cls] = mean_img
    
    # Plot results
    cols = 3
    rows = (len(classes) + cols - 1) // cols
    plt.figure(figsize=(cols*4, rows*4))
    
    for i, (cls, mean_img) in enumerate(mean_images.items()):
        plt.subplot(rows, cols, i+1)
        plt.imshow(mean_img)
        plt.title(f"Mean {cls}", fontsize=12)
        plt.axis("off")
    
    plt.tight_layout()
    if filename != None:
        plt.savefig(filename, dpi=150)
    plt.show()


def plot_median_images_per_class(df, dataset_path, filename=None):
    """
    Computes and plots the median image for each class.
    
    df: pandas DataFrame with a 'label' column
    dataset_path: path to folder containing dataset images
    filename (optional): filename of the PDF file where shown image will be dumped
    """
    classes = df['label'].unique()
    median_images = {}
    
    for cls in classes:
        imgs = []
        subset = df[df['label'] == cls]
        
        for _, row in subset.iterrows():
            img_path = os.path.join(dataset_path, "images", row['label'], row['filename'])
            try:
                img = Image.open(img_path).convert("RGB")
                imgs.append(np.array(img, dtype=np.float32))
            except:
                continue
        
        if imgs:
            # Stack into one array (N, H, W, C)
            imgs_stack = np.stack(imgs, axis=0)
            median_img = np.median(imgs_stack, axis=0) / 255.0  # normalize to [0,1]
            median_images[cls] = median_img
    
    # Plot results
    cols = 3
    rows = (len(classes) + cols - 1) // cols
    plt.figure(figsize=(cols*4, rows*4))
    
    for i, (cls, median_img) in enumerate(median_images.items()):
        plt.subplot(rows, cols, i+1)
        plt.imshow(median_img)
        plt.title(f"Median {cls}", fontsize=12)
        plt.axis("off")
    
    plt.tight_layout()
    if filename != None:
        plt.savefig(filename, dpi=150)
    plt.show()


def plot_pixel_distribution_correlation(df, dataset_path, bins=32):
    """
    Computes pixel color histograms per class and plots the correlation matrix.
    
    df: pandas DataFrame with 'filename' and 'label' columns
    dataset_path: path to the root dataset folder
    bins: number of bins per channel for the histogram
    """
    classes = df['label'].unique()
    histograms = {}
    
    for cls in classes:
        subset = df[df['label'] == cls]
        hist_accum = None
        
        for _, row in subset.iterrows():
            img_path = os.path.join(dataset_path, "images", row['label'], row['filename'])
            try:
                img = Image.open(img_path).convert("RGB")
                arr = np.array(img)
                hist, _ = np.histogramdd(
                    arr.reshape(-1, 3),
                    bins=(bins, bins, bins),
                    range=((0, 256), (0, 256), (0, 256))
                )
                if hist_accum is None:
                    hist_accum = hist
                else:
                    hist_accum += hist
            except:
                continue
        
        if hist_accum is not None:
            hist_flat = hist_accum.flatten()
            hist_flat = hist_flat / np.sum(hist_flat)  # normalize
            histograms[cls] = hist_flat
    
    # Build DataFrame with histograms
    hist_df = pd.DataFrame(histograms).T
    
    # Correlation matrix
    corr = hist_df.T.corr()
    
    # Plot heatmap
    plt.figure(figsize=(8, 6))
    sns.heatmap(corr, annot=True, cmap="flare", fmt=".2f", cbar=True)
    plt.title("Pixel Distribution Correlation Between Classes", fontsize=14)
    plt.show()


import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from PIL import Image
import os
from scipy.cluster.hierarchy import dendrogram, linkage
from scipy.spatial.distance import pdist

def plot_pixel_distribution_correlation_ordered(df, dataset_path, bins=32):
    """
    Computes pixel color histograms per class and plots the reordered correlation matrix
    using hierarchical clustering for better visualization.
    
    df: pandas DataFrame with 'filename' and 'label' columns
    dataset_path: path to the root dataset folder
    bins: number of bins per channel for the histogram
    """
    classes = df['label'].unique()
    histograms = {}
    
    # Build histograms per class
    for cls in classes:
        subset = df[df['label'] == cls]
        hist_accum = None
        
        for _, row in subset.iterrows():
            img_path = os.path.join(dataset_path, "images", row['label'], row['filename'])
            try:
                img = Image.open(img_path).convert("RGB")
                arr = np.array(img)
                hist, _ = np.histogramdd(
                    arr.reshape(-1, 3),
                    bins=(bins, bins, bins),
                    range=((0, 256), (0, 256), (0, 256))
                )
                if hist_accum is None:
                    hist_accum = hist
                else:
                    hist_accum += hist
            except:
                continue
        
        if hist_accum is not None:
            hist_flat = hist_accum.flatten()
            hist_flat = hist_flat / np.sum(hist_flat)  # normalize
            histograms[cls] = hist_flat
    
    # Build DataFrame with histograms
    hist_df = pd.DataFrame(histograms).T
    
    # Correlation matrix
    corr = hist_df.T.corr()
    
    # Reorder using hierarchical clustering
    condensed_distances = pdist(corr.values, metric='euclidean')
    linkage_matrix = linkage(condensed_distances, method='average')
    dendro = dendrogram(linkage_matrix, no_plot=True)
    reorder_idx = dendro['leaves']
    
    # Reordered matrix
    corr_reordered = corr.values[reorder_idx][:, reorder_idx]
    classes_reordered = [corr.index[i] for i in reorder_idx]
    
    # Plot
    plt.figure(figsize=(8, 6))
    sns.heatmap(
        corr_reordered,
        cmap="magma",
        #vmin=0,     # restrict scale to [0,1]
        #vmax=1,
        #center=0.5,
        #square=True,
        #linewidths=0.5,
        annot=True,       # show numbers
        fmt=".2f",        # format numbers
        #cbar_kws={"shrink": 0.8},
        xticklabels=classes_reordered,
        yticklabels=classes_reordered
    )
    plt.title("Pixel Distribution Correlation (Reordered)", fontsize=14, fontweight="bold")
    plt.xticks(rotation=45, ha='right')
    plt.yticks(rotation=0)
    plt.tight_layout()
    plt.show()


plot_mean_images_per_class(
    df,
    DATASET_PATH,
    os.path.join('..', 'reports', 'figures', 'EDA', 'class_prototypes_mean.pdf')
)


plot_median_images_per_class(
    df,
    DATASET_PATH,
    os.path.join('..', 'reports', 'figures', 'EDA', 'class_prototypes_median.pdf')
)


plot_pixel_distribution_correlation_ordered(
    df,
    DATASET_PATH,
    bins=256
)


from scipy.cluster.hierarchy import linkage, leaves_list
from sklearn.metrics.pairwise import cosine_similarity


classes = df['label'].unique()
mean_images = {}

for cls in classes:
    imgs = []
    subset = df[df['label'] == cls]
    
    for _, row in subset.iterrows():
        img_path = os.path.join(DATASET_PATH, "images", row['label'], row['filename'])
        try:
            img = Image.open(img_path).convert("RGB")
            imgs.append(np.array(img, dtype=np.float32))
        except:
            continue
    
    if imgs:
        mean_img = np.mean(imgs, axis=0) / 255.0  # normalize to [0,1]
        mean_images[cls] = mean_img


# Convert dict of mean images to 2D array (n_classes x flattened_pixels)
X = np.array([img.flatten() for img in mean_images.values()])

# Compute cosine similarity
cos_sim = cosine_similarity(X)

# Put into a DataFrame for readability
cos_sim_df = pd.DataFrame(cos_sim, index=mean_images.keys(), columns=mean_images.keys())
print(cos_sim_df)


for img in mean_images.values():
    display(img.shape)
    break


# Convert dict of mean images to 2D array (n_classes x flattened_pixels)
X_red = np.array([img[:,:,0].flatten() for img in mean_images.values()])

# Compute cosine similarity
cos_sim = cosine_similarity(X_red)

# Put into a DataFrame for readability
cos_sim_df = pd.DataFrame(cos_sim, index=mean_images.keys(), columns=mean_images.keys())
print(cos_sim_df)


# Convert dict of mean images to 2D array (n_classes x flattened_pixels)
X_green = np.array([img[:,:,1].flatten() for img in mean_images.values()])

# Compute cosine similarity
cos_sim = cosine_similarity(X_green)

# Put into a DataFrame for readability
cos_sim_df = pd.DataFrame(cos_sim, index=mean_images.keys(), columns=mean_images.keys())
print(cos_sim_df)


# Convert dict of mean images to 2D array (n_classes x flattened_pixels)
X_blue = np.array([img[:,:,2].flatten() for img in mean_images.values()])

# Compute cosine similarity
cos_sim = cosine_similarity(X_blue)

# Put into a DataFrame for readability
cos_sim_df = pd.DataFrame(cos_sim, index=mean_images.keys(), columns=mean_images.keys())
print(cos_sim_df)



